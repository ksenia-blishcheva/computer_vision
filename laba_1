import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from tqdm import tqdm
import numpy as np

# Конфигурация
CONFIG = {
    'data_dir': './data',
    'batch_size': 64,
    'lr': 0.001,
    'epochs': 10,
    'dropout': 0.3
}

# Подготовка данных
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_set = datasets.MNIST(CONFIG['data_dir'], train=True,
                           download=True, transform=transform)
val_set = datasets.MNIST(CONFIG['data_dir'], train=False,
                         download=True, transform=transform)

train_loader = DataLoader(train_set, CONFIG['batch_size'], shuffle=True)
val_loader = DataLoader(val_set, CONFIG['batch_size'], shuffle=False)

# Модель
model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(784, 256),
    nn.ReLU(),
    nn.Dropout(CONFIG['dropout']),
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.Dropout(CONFIG['dropout']),
    nn.Linear(128, 10)
)

optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['lr'])

# Обучение
for epoch in range(CONFIG['epochs']):
    # Фаза обучения
    model.train()
    for X, y in tqdm(train_loader, desc=f'Epoch {epoch + 1}'):
        optimizer.zero_grad()
        loss = F.cross_entropy(model(X), y)
        loss.backward()
        optimizer.step()

    # Фаза валидации
    model.eval()
    with torch.no_grad():
        losses, accuracies = zip(*[
            (
                F.cross_entropy(model(X), y).item(),
                (model(X).argmax(1) == y).float().mean().item()
            )
            for X, y in val_loader
        ])

    print(f'Epoch {epoch + 1:2d} | '
          f'Val Loss: {np.mean(losses):.4f} | '
          f'Val Acc: {np.mean(accuracies):.4f}')